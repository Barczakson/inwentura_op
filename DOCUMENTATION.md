# Excel Inventory Manager - Complete Documentation

## üìã Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture & Technology Stack](#architecture--technology-stack)
3. [Feature Documentation](#feature-documentation)
4. [Flexible Excel Upload Feature](#-flexible-excel-upload-feature)
5. [API Documentation](#api-documentation)
6. [Database Schema](#database-schema)
7. [Development Guide](#development-guide)
8. [Deployment Guide](#deployment-guide)
9. [Known Issues](#known-issues)
10. [Bug Reports](#bug-reports)
11. [Future Improvements](#future-improvements)
12. [Iteration Roadmap](#iteration-roadmap)

---

## üìä Project Overview

The Excel Inventory Manager is a comprehensive web application designed for managing inventory data through Excel file uploads with advanced monthly comparison capabilities.

### Key Features
- **Excel File Processing**: Upload .xlsx/.xls files with automatic parsing
- **Flexible Column Mapping**: Handle various Excel file structures with our column mapping interface
- **Data Aggregation**: Automatic grouping by item ID, name, and unit
- **Monthly Comparison**: Dedicated comparison page for analyzing inventory changes
- **Real-time Updates**: WebSocket integration for live data updates
- **Unit Conversion**: Smart display optimization (1000g ‚Üí 1kg)
- **Export Functionality**: Export processed data back to Excel
- **Manual Entry**: Add inventory items directly through forms

### Target Users
- Inventory managers
- Small to medium businesses
- Warehouse operators
- Supply chain professionals

---

## üèóÔ∏è Architecture & Technology Stack

### Frontend Stack
```
Next.js 15 (App Router)
‚îú‚îÄ‚îÄ React 19
‚îú‚îÄ‚îÄ TypeScript
‚îú‚îÄ‚îÄ Tailwind CSS 4
‚îú‚îÄ‚îÄ shadcn/ui components
‚îú‚îÄ‚îÄ TanStack Query (state management)
‚îú‚îÄ‚îÄ Zustand (global state)
‚îú‚îÄ‚îÄ React Dropzone (file uploads)
‚îî‚îÄ‚îÄ Recharts (data visualization)
```

### Backend Stack
```
Custom Node.js Server
‚îú‚îÄ‚îÄ Next.js API Routes
‚îú‚îÄ‚îÄ Socket.IO (WebSocket)
‚îú‚îÄ‚îÄ Prisma ORM
‚îú‚îÄ‚îÄ SQLite (dev) / PostgreSQL (prod)
‚îú‚îÄ‚îÄ XLSX library (Excel processing)
‚îî‚îÄ‚îÄ Express.js integration
```

### Development Tools
```
Development Environment
‚îú‚îÄ‚îÄ nodemon (server watching)
‚îú‚îÄ‚îÄ ESLint (code linting)
‚îú‚îÄ‚îÄ Prettier (code formatting)
‚îú‚îÄ‚îÄ Jest + Testing Library (testing)
‚îú‚îÄ‚îÄ TypeScript compiler
‚îî‚îÄ‚îÄ Prisma Studio (database GUI)
```

---

## üéØ Feature Documentation

### 1. Excel File Upload & Processing

**Location**: `/src/app/page.tsx`, `/src/app/api/excel/upload/route.ts`

**How it works**:
1. User drags/drops Excel file or clicks to browse
2. File validation (type, size checks)
3. Server processes with XLSX library
4. Data extraction with column mapping
5. Automatic aggregation by (itemId, name, unit)
6. Database storage (raw + aggregated)

**Supported Formats**:
- `.xlsx` (Excel 2007+)
- `.xls` (Excel 97-2003)

**Column Mapping**:
```typescript
// With ID column
{ 'Nr indeksu': 'A001', 'Nazwa towaru': 'Product', 'Ilosc': 10, 'Jednostka': 'kg' }

// Without ID column
{ 'Nazwa towaru': 'Product', 'Ilosc': 10, 'Jednostka': 'kg' }
```

**Data Flow**:
```
Excel File ‚Üí Parse ‚Üí Validate ‚Üí Aggregate ‚Üí Store ‚Üí Display
```

### 2. Monthly Comparison System

**Location**: `/src/app/comparison/page.tsx`

**Features**:
- **Separate Page**: Dedicated `/comparison` route
- **File Upload**: Previous month Excel file processing
- **Comparison Options**: Use current data or upload new current month file
- **Analysis Engine**: Detects new, missing, increased, decreased items
- **Alert System**: Categorized notifications (critical, warning, info)
- **Detailed Reports**: Percentage changes, quantity differences

**Comparison Algorithm**:
```typescript
analyzeInventoryDifferences(previous: Item[], current: Item[]) {
  // Creates maps keyed by: itemId_name_unit
  // Compares quantities and generates difference objects
  // Calculates percentage changes
  // Sorts by significance (largest differences first)
}
```

**Alert Categories**:
- üö® **Critical**: Missing products, significant decreases (‚â•50 units)
- ‚ö†Ô∏è **Warning**: Moderate decreases (‚â•10 units)
- üìà **Info**: Increases (‚â•20 units), new products

### 3. Data Management

**Data Tables**: Interactive tables with:
- Sorting and filtering
- Inline editing (double-click quantity)
- Bulk selection and deletion
- Export functionality
- Real-time updates

**CRUD Operations**:
- **Create**: Manual entry form, Excel upload
- **Read**: Data tables, API endpoints
- **Update**: Inline editing, edit dialogs
- **Delete**: Individual/bulk deletion

### 4. Unit Conversion System

**Location**: `/src/lib/unit-conversion.ts`

**Automatic Conversions**:
- 1000+ grams ‚Üí kilograms
- 1000+ milligrams ‚Üí grams
- 1000+ milliliters ‚Üí liters
- 128+ fluid ounces ‚Üí gallons

**Precision Control**: Configurable decimal places (default: 2)

### 5. Real-time Features

**WebSocket Integration**: Socket.IO server at `/api/socketio`
- Real-time data updates
- Connection status monitoring
- Graceful reconnection handling

---

## üìÅ Flexible Excel Upload Feature

The Excel Inventory Manager now supports flexible Excel file uploads with column mapping, allowing users to process Excel files with various structures.

### How It Works

1. When you upload an Excel file, the application analyzes its structure
2. The column mapping interface appears, showing sample data from each column
3. The system attempts to auto-detect column types based on headers and sample values
4. Users can manually adjust column mappings if needed
5. Once confirmed, the file is processed using the specified column mapping

### Supported Column Types

- **Item ID** (Optional): Unique identifier for items
- **Name** (Required): Product/item name
- **Quantity** (Required): Numeric quantity value
- **Unit** (Required): Measurement unit (kg, g, l, ml, szt, etc.)

### Auto-Detection Logic

The system uses pattern matching to auto-detect column types:
- **Item ID**: Looks for columns with headers containing "nr", "indeks", "id" or values matching item ID patterns
- **Name**: Looks for columns with headers containing "nazwa", "towar", "produkt", "item" or text values longer than 3 characters
- **Quantity**: Looks for columns with headers containing "ilo", "szt", "ilo≈õƒá", "quantity", "amount" or numeric values
- **Unit**: Looks for columns with headers containing "jmz", "jednostka", "unit", "szt", "kg", "l", "ml", "g" or standard unit values

### Benefits

- Process Excel files with different column orders
- Handle files with additional or missing columns
- Support custom Excel templates
- Reduce errors from fixed column assumptions

---

## üîå API Documentation

### File Upload Endpoints

#### `POST /api/excel/upload`
Upload and process Excel files.

**Request**: `multipart/form-data`
```typescript
FormData {
  file: File // .xlsx or .xls file
}
```

**Response**: `200 OK`
```json
{
  "fileId": "cmebrroqc0000i081eh7kbd0g",
  "rows": [/* raw Excel rows */],
  "aggregated": [/* aggregated items */],
  "message": "File processed successfully"
}
```

**Errors**:
- `400`: No file, invalid type, processing error
- `500`: Database or server error

#### `GET /api/excel/data`
Retrieve inventory data.

**Query Parameters**:
- `fileId`: Filter by specific file
- `includeRaw`: Include raw Excel data

**Response**: `200 OK`
```json
{
  "aggregated": [
    {
      "id": "item-id",
      "itemId": "A001",
      "name": "Product Name",
      "quantity": 10,
      "unit": "kg",
      "fileId": "file-id",
      "sourceFiles": ["file1", "file2"],
      "count": 2
    }
  ],
  "raw": [/* if includeRaw=true */]
}
```

#### `PUT /api/excel/data`
Update item quantity.

**Request**: `application/json`
```json
{
  "id": "item-id",
  "quantity": 25
}
```

**Response**: `200 OK` - Updated item object

#### `DELETE /api/excel/data?id={itemId}`
Delete inventory item.

**Response**: `200 OK`
```json
{
  "message": "Item deleted successfully"
}
```

### File Management

#### `GET /api/excel/files`
List uploaded files.

**Response**: `200 OK`
```json
[
  {
    "id": "file-id",
    "name": "inventory.xlsx",
    "size": 15360,
    "uploadDate": "2025-08-15T14:00:00Z",
    "rowCount": 150
  }
]
```

#### `DELETE /api/excel/files?id={fileId}`
Delete uploaded file and associated data.

### Export Endpoint

#### `GET /api/excel/export?type={aggregated|raw}`
Export data to Excel format.

**Response**: `200 OK` - Excel file download

### Manual Entry

#### `POST /api/excel/manual`
Add manual inventory entry.

**Request**: `application/json`
```json
{
  "itemId": "A001", // optional
  "name": "Product Name",
  "quantity": 10,
  "unit": "kg"
}
```

---

## üóÑÔ∏è Database Schema

The application uses Prisma ORM with support for both SQLite (development) and PostgreSQL (production). The schema includes 6 primary models:

### Prisma Models

```prisma
model User {
  id        String   @id @default(cuid())
  email     String   @unique
  name      String?
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  @@map("users")
}

model Post {
  id        String   @id @default(cuid())
  title     String
  content   String?
  published Boolean  @default(false)
  authorId  String
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  @@map("posts")
}

model ExcelFile {
  id               String   @id @default(cuid())
  fileName         String
  fileSize         Int
  rowCount         Int?     @default(0)
  uploadDate       DateTime @default(now())
  originalStructure Json?   // JSON for PostgreSQL
  columnMapping    Json?    // Applied column mapping for this file
  detectedHeaders  Json?    // Headers detected in this file
  rows             ExcelRow[]
  aggregated       AggregatedItem[]

  @@index([uploadDate])
  @@map("excel_files")
}

model ExcelRow {
  id               String    @id @default(cuid())
  itemId           String?
  name             String
  quantity         Float
  unit             String
  originalRowIndex Int?      // Position in original Excel file
  fileId           String
  file             ExcelFile @relation(fields: [fileId], references: [id], onDelete: Cascade)
  createdAt        DateTime  @default(now())

  @@index([itemId, name, unit])
  @@index([fileId])
  @@index([name]) // For name-based searches
  @@index([createdAt]) // For time-based queries
  @@index([fileId, originalRowIndex]) // For file-specific ordering
  @@map("excel_rows")
}

model AggregatedItem {
  id          String     @id @default(cuid())
  itemId      String?
  name        String
  quantity    Float
  unit        String
  fileId      String?
  file        ExcelFile? @relation(fields: [fileId], references: [id], onDelete: Cascade)
  sourceFiles Json?      // JSON array of file IDs
  count       Int?       @default(1)
  createdAt   DateTime   @default(now())
  updatedAt   DateTime   @updatedAt

  @@unique([itemId, name, unit], name: "itemId_name_unit")
  @@index([itemId, name, unit])
  @@index([fileId])
  @@index([name]) // For name-based searches
  @@index([quantity]) // For quantity-based sorting
  @@index([updatedAt]) // For recently updated items
  @@index([count]) // For count-based queries
  @@map("aggregated_items")
}

model ColumnMapping {
  id          String   @id @default(cuid())
  name        String   // User-friendly name for this mapping
  description String?  // Optional description
  isDefault   Boolean  @default(false)
  mapping     Json     // Column mapping configuration as JSON
  headers     Json?    // Sample headers this mapping was created for
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
  
  // Track usage
  usageCount  Int      @default(0)
  lastUsed    DateTime?
  
  @@index([isDefault])
  @@index([usageCount])
  @@index([lastUsed])
  @@map("column_mappings")
}
```

### Key Relationships
- **ExcelFile** ‚Üí **ExcelRow** (1:many, cascade delete)
- **ExcelFile** ‚Üí **AggregatedItem** (1:many, cascade delete)
- **Unique Constraint**: AggregatedItem(itemId, name, unit)
- **Indexes**: Multiple indexes for performance optimization

### Environment-Specific Configurations

#### Local Development (.env.local)
Uses SQLite for simplicity:
```
DATABASE_URL="file:./prisma/dev.db"
DIRECT_URL="file:./prisma/dev.db"
```

#### Production Deployment (.env.production)
Uses PostgreSQL with Vercel + Supabase optimization:
```
# Transaction pooler (port 6543) - for serverless functions on Vercel
DATABASE_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1&pool_timeout=20&sslmode=require"

# Session pooler (port 5432) - for migrations
DIRECT_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].pooler.supabase.com:5432/postgres?sslmode=require"
```

### Migration Commands
```bash
# Generate Prisma client
npm run db:generate

# Apply migrations to development database
npm run db:push

# Deploy migrations to production
npm run db:deploy

# Reset development database
npm run db:reset

# Open Prisma Studio (database GUI)
npm run db:studio
```

---

## üõ†Ô∏è Development Guide

### Prerequisites
```bash
Node.js 18+
npm 9+
Git
```

### Setup Instructions
```bash
# Clone repository
git clone <repository-url>
cd excel-inventory-manager

# Install dependencies
npm install

# Set up database
npm run db:push
npm run db:generate

# Start development server
npm run dev
```

### Available Scripts
```bash
npm run dev          # Development server with hot reload
npm run build        # Production build
npm run start        # Production server
npm run lint         # ESLint checking
npm run test         # Run tests
npm run test:watch   # Tests in watch mode
npm run test:coverage # Coverage report

# Database commands
npm run db:push      # Push schema changes
npm run db:generate  # Generate Prisma client
npm run db:migrate   # Run migrations
npm run db:reset     # Reset database
npm run db:studio    # Open Prisma Studio
npm run db:seed      # Seed database
```

### Environment Variables
```env
# Database - SQLite for Development
DATABASE_URL="file:./prisma/dev.db"
DIRECT_URL="file:./prisma/dev.db"

# Database - PostgreSQL for Production
# Uncomment and update these for production:
# DATABASE_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1&pool_timeout=20&sslmode=require"
# DIRECT_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].pooler.supabase.com:5432/postgres?sslmode=require"

# Next.js
NEXTAUTH_URL="http://localhost:3000"
NEXTAUTH_SECRET="your-secret-key"

# Optional
NODE_ENV="development"
PORT=3000
```

### Database Development Commands
```bash
# Development database commands
npm run db:generate     # Generate Prisma client
npm run db:push         # Push schema changes to development DB
npm run db:reset        # Reset development database
npm run db:studio       # Open Prisma Studio (GUI)
npm run db:seed         # Seed development database

# Production database commands
npm run db:deploy       # Deploy migrations to production
npm run db:migrate      # Run migrations
```

### Database Testing
```bash
# Run database-specific tests
npm run test:api -- --testPathPatterns=db

# Run all integration tests
npm run test:integration

# Run database connection tests
npm run test:api -- --testPathPatterns=database-connection

# Run database schema tests
npm run test:api -- --testPathPatterns=database-schema
```

### Project Structure
```
src/
‚îú‚îÄ‚îÄ app/                    # Next.js App Router
‚îÇ   ‚îú‚îÄ‚îÄ api/               # API routes
‚îÇ   ‚îú‚îÄ‚îÄ comparison/        # Monthly comparison page
‚îÇ   ‚îú‚îÄ‚îÄ globals.css        # Global styles
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx         # Root layout
‚îÇ   ‚îî‚îÄ‚îÄ page.tsx           # Home page
‚îú‚îÄ‚îÄ components/            # React components
‚îÇ   ‚îú‚îÄ‚îÄ ui/               # shadcn/ui components
‚îÇ   ‚îú‚îÄ‚îÄ data-table.tsx    # Main data table
‚îÇ   ‚îú‚îÄ‚îÄ data-charts.tsx   # Charts component
‚îÇ   ‚îî‚îÄ‚îÄ edit-item-dialog.tsx
‚îú‚îÄ‚îÄ lib/                   # Utility libraries
‚îÇ   ‚îú‚îÄ‚îÄ db-config.ts      # Database configuration and connection
‚îÇ   ‚îú‚îÄ‚îÄ server-optimizations.ts # Server performance optimizations
‚îÇ   ‚îú‚îÄ‚îÄ migrate.ts        # Runtime migration utilities
‚îÇ   ‚îú‚îÄ‚îÄ socket.ts         # Socket.IO setup
‚îÇ   ‚îî‚îÄ‚îÄ unit-conversion.ts # Unit conversion utilities
‚îú‚îÄ‚îÄ hooks/                 # Custom React hooks
‚îÇ   ‚îî‚îÄ‚îÄ use-toast.ts      # Toast notifications
‚îî‚îÄ‚îÄ types/                 # TypeScript type definitions

prisma/
‚îú‚îÄ‚îÄ schema.prisma         # Database schema
‚îî‚îÄ‚îÄ seed.ts              # Database seeding

__tests__/                # Test files
‚îú‚îÄ‚îÄ integration/         # Integration tests
‚îÇ   ‚îú‚îÄ‚îÄ database-connection.test.ts   # Database connection tests
‚îÇ   ‚îú‚îÄ‚îÄ database-requests.test.ts    # Database request tests
‚îÇ   ‚îú‚îÄ‚îÄ db-config.test.ts            # Database configuration tests
‚îÇ   ‚îú‚îÄ‚îÄ db-connection.test.ts        # Database connection verification tests
‚îÇ   ‚îú‚îÄ‚îÄ db-schema.test.ts            # Database schema verification tests
‚îÇ   ‚îî‚îÄ‚îÄ column-mapping-flow.test.ts  # Column mapping integration tests
‚îî‚îÄ‚îÄ simple.test.ts       # Basic tests

Configuration files:
‚îú‚îÄ‚îÄ jest.config.js       # Jest configuration
‚îú‚îÄ‚îÄ jest.setup.js        # Test setup
‚îú‚îÄ‚îÄ next.config.js       # Next.js configuration
‚îú‚îÄ‚îÄ tailwind.config.js   # Tailwind CSS
‚îú‚îÄ‚îÄ tsconfig.json        # TypeScript
‚îî‚îÄ‚îÄ server.ts            # Custom server
```

---

## üöÄ Deployment Guide

### Production Build
```bash
# Build application
npm run build

# Test production build locally
npm run start
```

### Environment Setup
```env
# Production database - PostgreSQL with Supabase
# Transaction pooler (port 6543) - for serverless functions on Vercel
DATABASE_URL="postgresql://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1&pool_timeout=20&sslmode=require"

# Session pooler (port 5432) - for migrations (IPv4 compatible, NOT direct connection)
DIRECT_URL="postgresql://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].pooler.supabase.com:5432/postgres?sslmode=require"

# Security
NEXTAUTH_URL="https://your-domain.com"
NEXTAUTH_SECRET="secure-random-string"

# Performance
NODE_ENV="production"
```

### Database Setup for Production

1. **Create Supabase Project**:
   - Sign up at https://supabase.com/
   - Create a new project
   - Note your project credentials

2. **Configure Environment Variables**:
   ```bash
   # In Vercel dashboard, add these environment variables:
   DATABASE_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1&pool_timeout=20&sslmode=require"
   DIRECT_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].pooler.supabase.com:5432/postgres?sslmode=require"
   ```

3. **Run Database Migrations**:
   ```bash
   # Generate Prisma client
   npm run db:generate
   
   # Deploy migrations to production database
   npm run db:deploy
   ```

4. **Verify Database Schema**:
   ```bash
   # Open Prisma Studio to verify tables
   npm run db:studio
   ```

### Database Connection Parameters Explained

- **pgbouncer=true**: Enables connection pooling for Vercel serverless functions
- **connection_limit=1**: Limits connections to 1 per serverless function (required for Vercel)
- **pool_timeout=20**: Sets connection pool timeout to 20 seconds
- **sslmode=require**: Enforces SSL encryption for secure connections
- **Transaction Pooler (6543)**: Used for application connections in serverless functions
- **Session Pooler (5432)**: Used for database migrations

### Deployment Options

#### 1. Vercel (Recommended)
```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel

# Environment variables in Vercel dashboard:
# - DATABASE_URL
# - NEXTAUTH_SECRET
```

#### 2. Docker
```dockerfile
# Dockerfile example
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build
EXPOSE 3000
CMD ["npm", "start"]
```

#### 3. Traditional Hosting
```bash
# Build and start
npm run build
npm run start

# Process manager (PM2)
npm install -g pm2
pm2 start npm --name "inventory-app" -- start
```

### Database Migration
```bash
# Production database setup
npx prisma migrate deploy
npx prisma generate
```

---

## ‚ö†Ô∏è Known Issues

### 1. **File Upload Size Limitation**
**Issue**: Large Excel files (>10MB) may cause timeout errors
**Workaround**: Split large files into smaller chunks
**Status**: üîÑ In Progress
**Priority**: Medium

### 2. **Socket.IO Connection Drops**
**Issue**: WebSocket connections occasionally drop in production
**Workaround**: Automatic reconnection implemented
**Status**: üîç Monitoring
**Priority**: Low

### 3. **Jest Configuration Warnings**
**Issue**: `moduleNameMapping` validation warnings in Jest
**Impact**: Tests run successfully but show warnings
**Status**: üêõ Known Issue
**Priority**: Low
**Note**: This is a minor issue that doesn't affect functionality. Main application errors have been resolved.

### 4. **Memory Usage on Large Datasets**
**Issue**: High memory consumption with 1000+ items
**Workaround**: Implement pagination for large datasets
**Status**: üîÑ Planned
**Priority**: Medium

### 5. **Excel Formula Support**
**Issue**: Excel formulas are not evaluated, only raw values
**Limitation**: By design - XLSX library limitation
**Status**: ‚úÖ Expected Behavior
**Priority**: Enhancement

---

## üêõ Bug Reports

### Critical Bugs (P0)

#### 1. Data Loss on File Deletion ‚úÖ FIXED
**Description**: Aggregated data disappeared when deleting any file
**Root Cause**: Clearing all data instead of reloading remaining data
**Fix**: Modified `handleDeleteFile` to reload data after deletion
**Status**: ‚úÖ Resolved
**Fixed In**: Current version

#### 2. Error Handler Runtime Errors ‚úÖ FIXED
**Description**: Application crashed with "Cannot read property 'toUpperCase' of undefined" when handling API errors
**Root Cause**: Error objects not properly validated in error handler functions
**Fix**: Added defensive programming and validation in `showErrorToast` and `handleAsyncOperation` functions
**Status**: ‚úÖ Resolved
**Fixed In**: Current version

### High Priority Bugs (P1)

#### 3. Placeholder Content in Tables ‚úÖ FIXED
**Description**: Data tables showed placeholder text instead of actual data
**Root Cause**: Hardcoded placeholder divs in render logic
**Fix**: Replaced with proper DataTable components
**Status**: ‚úÖ Resolved
**Fixed In**: Current version

#### 4. Unit Conversion Edge Cases
**Description**: Conversion fails with very small decimal values
**Example**: 0.0001 grams shows as "0.00 g" instead of "0.1 mg"
**Status**: üîç Under Investigation
**Priority**: High

### Medium Priority Bugs (P2)

#### 4. File Name Encoding Issues
**Description**: Non-ASCII characters in file names cause display issues
**Impact**: Affects international users
**Status**: üìù Reported
**Priority**: Medium

#### 5. Date Formatting in Exports
**Description**: Date columns in Excel exports use system timezone
**Expected**: UTC or user-defined timezone
**Status**: üìù Reported
**Priority**: Medium

### Low Priority Bugs (P3)

#### 6. Toast Notification Positioning
**Description**: Success messages sometimes overlap
**Impact**: Minor UX issue
**Status**: üìù Backlog
**Priority**: Low

#### 7. Dark Mode Compatibility
**Description**: Some components don't respect dark mode preferences
**Status**: üìù Enhancement
**Priority**: Low

---

## üöÄ Future Improvements

### Short Term (Next 2-4 weeks)

#### 1. **Enhanced Data Validation**
**Priority**: High
**Effort**: Medium
**Description**: 
- Implement comprehensive input validation
- Add data type checking for quantities
- Validate unit consistency
- Error messages for invalid data formats

**Implementation**:
```typescript
// Enhanced validation schema
const ItemValidationSchema = z.object({
  itemId: z.string().optional(),
  name: z.string().min(1, "Name is required"),
  quantity: z.number().positive("Quantity must be positive"),
  unit: z.enum(["kg", "g", "l", "ml", "szt", "m"]),
})
```

#### 2. **Improved Error Handling** ‚úÖ PARTIALLY COMPLETED
**Priority**: High
**Effort**: Low
**Description**:
- User-friendly error messages
- Retry mechanisms for failed operations
- Progressive error recovery
- Error logging and monitoring

**Recent Fixes**:
- Added validation in `showErrorToast` to handle cases where `error.type` might be undefined or invalid
- Added defensive programming in `handleAsyncOperation` to ensure error objects conform to the `AppError` interface
- Added fallback handling for unknown error types
- Enhanced error logging for debugging purposes

**Remaining Work**:
- Implement retry mechanisms for failed operations
- Add progressive error recovery

#### 3. **Performance Optimization**
**Priority**: Medium
**Effort**: Medium
**Description**:
- Implement virtual scrolling for large datasets
- Add pagination to data tables
- Optimize database queries
- Client-side caching improvements

```typescript
// Virtual scrolling implementation
import { useVirtualizer } from '@tanstack/react-virtual'

const VirtualizedTable = ({ data, height = 400 }) => {
  const virtualizer = useVirtualizer({
    count: data.length,
    getScrollElement: () => parentRef.current,
    estimateSize: () => 45,
  })
  // ... implementation
}
```

### Medium Term (1-3 months)

#### 4. **Advanced Analytics Dashboard**
**Priority**: High
**Effort**: High
**Description**:
- Inventory trend analysis
- Predictive analytics for stock levels
- Custom date range comparisons
- Interactive charts and graphs

**Features**:
- üìä Monthly/quarterly trend charts
- üìà Stock level predictions
- üéØ Low stock alerts
- üìâ Usage pattern analysis

#### 5. **Multi-tenant Support**
**Priority**: Medium
**Effort**: High
**Description**:
- User authentication system
- Organization management
- Role-based access control
- Data isolation between tenants

**Schema Changes**:
```prisma
model Organization {
  id    String @id @default(cuid())
  name  String
  users User[]
  files ExcelFile[]
}

model User {
  id             String       @id @default(cuid())
  email          String       @unique
  organizationId String
  role           Role
  organization   Organization @relation(fields: [organizationId], references: [id])
}
```

#### 6. **API Rate Limiting & Security**
**Priority**: High
**Effort**: Medium
**Description**:
- Implement rate limiting
- API authentication
- Input sanitization
- CSRF protection

#### 7. **Advanced Export Features**
**Priority**: Medium
**Effort**: Medium
**Description**:
- Custom export templates
- Multiple format support (CSV, PDF, JSON)
- Scheduled exports
- Email export delivery

### Long Term (3-6 months)

#### 8. **Mobile Application**
**Priority**: Medium
**Effort**: High
**Description**:
- React Native mobile app
- Offline data synchronization
- Barcode scanning integration
- Push notifications

#### 9. **Integration Platform**
**Priority**: Medium
**Effort**: High
**Description**:
- REST API for third-party integrations
- Webhook support
- Integration with popular inventory systems
- Import from multiple data sources

#### 10. **Machine Learning Features**
**Priority**: Low
**Effort**: Very High
**Description**:
- Automatic anomaly detection
- Demand forecasting
- Inventory optimization suggestions
- Pattern recognition in usage data

---

## üìã Iteration Roadmap

### Sprint 1 (Week 1-2): Stability & Polish
**Goal**: Fix remaining bugs and improve user experience

**Tasks**:
- [ ] Fix Jest configuration warnings
- [ ] Implement comprehensive error boundaries
- [ ] Add loading states for all async operations  
- [ ] Improve mobile responsiveness
- [ ] Add keyboard shortcuts for power users
- [ ] Implement proper form validation

**Deliverables**:
- Bug-free application
- Improved error handling
- Better mobile experience

### Sprint 2 (Week 3-4): Performance & Scalability
**Goal**: Optimize for larger datasets and better performance

**Tasks**:
- [ ] Implement virtual scrolling
- [ ] Add pagination to data tables
- [ ] Optimize database queries
- [ ] Add data export chunking
- [ ] Implement caching strategy
- [ ] Performance monitoring setup

**Deliverables**:
- Support for 10,000+ inventory items
- <2s page load times
- Efficient memory usage

### Sprint 3 (Week 5-6): Enhanced Analytics
**Goal**: Add advanced comparison and analytics features

**Tasks**:
- [ ] Historical trend analysis
- [ ] Custom date range comparisons
- [ ] Advanced filtering options
- [ ] Inventory health scoring
- [ ] Automated alert rules
- [ ] Export analytics reports

**Deliverables**:
- Advanced analytics dashboard
- Customizable alerts
- Trend analysis features

### Sprint 4 (Week 7-8): User Management
**Goal**: Add multi-user support and security

**Tasks**:
- [ ] User authentication system
- [ ] Role-based permissions
- [ ] Organization management
- [ ] Audit logging
- [ ] API security implementation
- [ ] Data backup/restore

**Deliverables**:
- Multi-tenant application
- Secure user management
- Audit trail functionality

### Sprint 5 (Week 9-10): Integration & Automation
**Goal**: Connect with external systems and automate workflows

**Tasks**:
- [ ] REST API development
- [ ] Webhook system
- [ ] Email notifications
- [ ] Scheduled reports
- [ ] Import from multiple sources
- [ ] Export automation

**Deliverables**:
- Public API
- Automated workflows
- Integration capabilities

### Sprint 6 (Week 11-12): Mobile & Advanced Features
**Goal**: Extend platform capabilities

**Tasks**:
- [ ] Mobile app development (React Native)
- [ ] Offline synchronization
- [ ] Barcode scanning
- [ ] Advanced search
- [ ] Bulk operations UI
- [ ] Custom dashboard widgets

**Deliverables**:
- Mobile application
- Offline capabilities
- Enhanced user experience

---

## üìû Support & Maintenance

### Monitoring & Logging
- Application performance monitoring
- Error tracking and alerting  
- User activity analytics
- Database performance metrics

### Backup Strategy
- Automated daily database backups
- File storage redundancy
- Disaster recovery procedures
- Data retention policies

### Update Process
- Semantic versioning
- Automated testing pipeline
- Staged deployment process
- Rollback procedures

### Documentation Maintenance
- Keep API documentation updated
- Update user guides
- Maintain developer documentation
- Regular architecture reviews

---

## üìù Contributing Guidelines

### Code Standards
- Follow TypeScript strict mode
- Use ESLint and Prettier
- Write tests for new features
- Document complex functions

### Pull Request Process
1. Create feature branch
2. Implement changes with tests
3. Update documentation
4. Submit PR with description
5. Code review process
6. Merge after approval

### Issue Reporting
- Use provided templates
- Include reproduction steps
- Attach relevant screenshots
- Label with priority level

---

*Last Updated: August 26, 2025*
*Version: 1.0.1*
*Maintainer: Development Team*